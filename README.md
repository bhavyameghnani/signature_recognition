# Signature Recognition
One can clone the repositories using the following commands
```
git clone https://github.com/parth-dedhia/signature_recognition.git
cd signature_recognition
```
#

Here you will see a couple of directories and a couple of python and json files.
The folders contains the dataset and are named as follows

* Dataset - This folder contains the genuine images of 12 users. 10per each. which is used for training the model. These images are similar to the drive link shared by the Axis Bank AI Challenge Competetion but few ids are corrected and modified as they were wrong previously.

* TestDriveData1 - Contains 10 Genuine signatures of 5 users for testing. (2 images per user) 

* TestDriveData2 -  Contains 10 Forged signatures of 5 users for testing. (2 images per user) 

The capsnet.ipnyb contains the code which is to runned.
On running the code , a separate folder called as the output folder will be created and in this folder the checkpoints and other tensorboard requirements will be stored and updated.
The checkpoints are loaded during the test time for loading the pre-trained variables.

# More on Checkpoints
The checkpoints are created by the code to store the variables. The purpose of this is to avoid running the entire model during test time.
There are few other files also generated by tensorflow. One can see more about these checkpoints in the tensorflow documentation

# Running the code
One can simply open the ipython notebook.
Its is suggestible to use the free GPU and TPU provided by google - Google Colaboratory.
Since the model consist of multiplication of rank 4 matrices, it would be suggestible to use a GPU if thr code is run on a local computer.
# Running the Model on Google Colab
Please follow the steps -
1) Clone and save the project locally.
2) Open Google colab and go to file->upload notebook->(upload the CapsNetSignatureModel.ipynb from your local machine).
3) Go to Runtime->changeRuntime->select python 3 and GPU.
4) DataSet link - https://drive.google.com/drive/folders/1FclUyojyK8HWSTR2OAosbAnPV0aj1kVm?usp=sharing
5) Download the dataset and Upload it in your Google drive under "Mydrive" (root folder of google-drive).
6) Run the first block and mount the drive on to g-colab.
7) Run the second block and upload the followings files from the cloned project which is saved on your local machine during the cloning process :-
a) hyperparameters.json(application/json) ,
b) logger.py(text/plain) ,
c) model_base.py(text/plain),
d) utils.py(text/plain).
8) Now simply run all the blocks. 
9) The model will train itself till 2700 epochs the stop and run the remaining blocks
10) Check out the value of softmax value of genuine and forged signature that will help to determine the validation capability of the model.

(Feel free to change the paths of dataset and the required .py files in the code , depending on where you store them.)

